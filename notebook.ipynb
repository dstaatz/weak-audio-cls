{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audioset import *\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "source": [
    "## Data importing from the google audioset\n",
    "\n",
    "Meta-data files are at `google_audioset_meta/*.csv`\n",
    "\n",
    "The `ontology.json` descibes the label ids.\n",
    "\n",
    "These have all the meta-data to show how each video segment is labeled.\n",
    "\n",
    "This meta-data is returned as a list of dicts"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'id': '/m/0dgw9r',\n",
       " 'name': 'Human sounds',\n",
       " 'description': 'Sounds produced by the human body through the actions of the individual.',\n",
       " 'citation_uri': '',\n",
       " 'positive_examples': [],\n",
       " 'child_ids': ['/m/09l8g',\n",
       "  '/m/01w250',\n",
       "  '/m/09hlz4',\n",
       "  '/m/0bpl036',\n",
       "  '/m/0160x5',\n",
       "  '/m/0k65p',\n",
       "  '/m/01jg02',\n",
       "  '/m/04xp5v',\n",
       "  '/t/dd00012'],\n",
       " 'restrictions': ['abstract']}"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Load in the ontology so we can know what the labels mean\n",
    "ontology = load_ontology()\n",
    "\n",
    "# Showing the format of one element\n",
    "ontology[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'ytid': '--PJHxphWEs',\n",
       "  'start_seconds': 30.0,\n",
       "  'end_seconds': 40.0,\n",
       "  'positive_labels': ['/m/09x0r', '/t/dd00088']},\n",
       " {'ytid': '--ZhevVpy1s',\n",
       "  'start_seconds': 50.0,\n",
       "  'end_seconds': 60.0,\n",
       "  'positive_labels': ['/m/012xff']},\n",
       " {'ytid': '--aE2O5G5WE',\n",
       "  'start_seconds': 0.0,\n",
       "  'end_seconds': 10.0,\n",
       "  'positive_labels': ['/m/03fwl', '/m/04rlf', '/m/09x0r']}]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Load in the meta data\n",
    "eval_meta = load_meta_csv(\"google_audioset_meta/eval_segments.csv\")\n",
    "balanced_meta = load_meta_csv(\"google_audioset_meta/balanced_train_segments.csv\")\n",
    "unbalanced_meta = load_meta_csv(\"google_audioset_meta/unbalanced_train_segments.csv\")\n",
    "\n",
    "# Showing the format of three elements\n",
    "balanced_meta[0:3]"
   ]
  },
  {
   "source": [
    "## Downloading data\n",
    "\n",
    "Now that we've loaded the meta-data, we can use it to download and store specific labels locally.\n",
    "\n",
    "Note: This is pretty stupid and will redownload the data, even if you already have it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading Hammer\n"
     ]
    }
   ],
   "source": [
    "# What labels do you want to work with?\n",
    "label = \"/m/03l9g\" # Hammer\n",
    "print(\"Downloading\", get_label_name_from_id(ontology, label))\n",
    "\n",
    "eval_folder = \"data/eval/\"\n",
    "# download_labeled(eval_folder, eval_meta, label)\n",
    "\n",
    "balanced_folder = \"data/balanced/\"\n",
    "# download_labeled(balanced_folder, balanced_meta, label)\n"
   ]
  },
  {
   "source": [
    "## Loading in Data\n",
    "\n",
    "Now that the data is downloaded to files, we need to get that data loaded into memory."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING: data/eval/hvHiJQL7_9s.wav was not found\nWARNING: data/eval/ijgwCwnKZUM.wav was not found\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(44100, array([1199,  891,  667, ..., 2986, 2439, 2018], dtype=int16)),\n",
       " (44100,\n",
       "  array([[  -78,   -78],\n",
       "         [ -131,  -131],\n",
       "         [ -190,  -190],\n",
       "         ...,\n",
       "         [-4478, -4478],\n",
       "         [-4899, -4899],\n",
       "         [-5308, -5308]], dtype=int16)),\n",
       " (44100,\n",
       "  array([[ -67,  -67],\n",
       "         [ -31,  -31],\n",
       "         [ -31,  -31],\n",
       "         ...,\n",
       "         [2786, 2786],\n",
       "         [3924, 3924],\n",
       "         [3510, 3510]], dtype=int16))]"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data = load_dataset_labeled(eval_folder, eval_meta, label)\n",
    "\n",
    "data[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}